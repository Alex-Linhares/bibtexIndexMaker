Increasing the statistical significance of entanglement detection in experiments
Bastian Jungnitsch,1 S®nke Niekamp,1 Matthias Kleinmann,1 Otfried G® hne,1, 2 o u He Lu,3 Wei-Bo Gao,3 Yu-Ao Chen,3, 4 Zeng-Bing Chen,3 and Jian-Wei Pan3, 4
1 Institut f®r Quantenoptik und Quanteninformation, u ® Osterreichische Akademie der Wissenschaften, Technikerstraﬂe 21A, A-6020 Innsbruck, Austria 2 Institut f®r Theoretische Physik, Universit®t Innsbruck, Technikerstraﬂe 25, A-6020 Innsbruck, Austria u a 3 Hefei National Laboratory for Physical Sciences at Microscale and Department of Modern Physics, University of Science and Technology of China, Hefei, Anhui 230026, China 4 Physikalisches Institut, Ruprecht-Karls-Universit®t Heidelberg, Philosophenweg 12, 69120 Heidelberg, Germany a (Dated: December 3, 2009)

arXiv:0912.0645v1 [quant-ph] 3 Dec 2009

Entanglement is often verified by a violation of an inequality like a Bell inequality or an entanglement witness. Considerable effort has been devoted to the optimization of such inequalities in order to obtain a high violation. We demonstrate theoretically and experimentally that such an optimization does not necessarily lead to a better entanglement test, if the statistical error is taken into account. Theoretically, we show for different error models that reducing the violation of an inequality can improve the significance. Experimentally, we observe this phenomenon in a four-photon experiment, testing the Mermin and Ardehali inequality for different levels of noise.

Introduction -- Quantum theory is a statistical theory, predicting in general only probabilities for experimental results. Consequently, in most experiments observing quantum effects, several copies of a quantum state are generated and individually measured, to determine the desired probabilities. As only a finite number of states can be generated, this leads to an unavoidable statistical error. Many of today's experiments aim at the generation of entanglement, which is considered as a central resource in quantum information processing [1, 2]. So far, entanglement of up to ten qubits has been achieved using trapped ions or photons [3, 4]. For the experimental verification of entanglement, often inequalities for the correlations -- such as Bell inequalities or entanglement witnesses -- are used [2], for which a violation indicates entanglement. The maximization of this violation has been investigated in detail, cf. Refs. [2, 5]. In fact, making such inequalities more sensitive is a crucial step in order to allow advanced experiments with more particles. In this paper we demonstrate theoretically and experimentally that such an optimization does not necessarily lead to a better entanglement test, if the statistical nature of quantum theory is taken into account. It was already noted [6] that, when aiming at ruling out local realism, highly entangled states do not necessarily deliver a stronger test than weakly entangled states, but this does not answer the question which inequality to use for a given state and it remains unclear how to apply it to actual error models used in experiments. In Ref. [7] different entanglement detection methods for two qubits have been compared, but most of these methods cannot be applied to multiparticle systems. From the theoretical side, we show for different error models that decreasing the violation of an inequality can improve the significance. Experimentally, we demonstrate this phenomenon in a four-photon experiment, in

which we measure the Mermin and Ardehali inequality and find that the former inequality leads to a higher significance than the latter, despite of a lower violation. Finally, we discuss consequences for future experiments and possible applications to other problems. Statement of the problem -- A witness W is an observable which has a non-negative expectation value on all separable states (that is, states which can be written as a mixture of product states, = k pk |ak , bk ak , bk | with some probabilities pk ). Hence, a negative expectation value of a witness signals the presence of entanglement. Similarly, a Bell inequality is an inequality B  Clhv where B is a sum of certain correlation terms and which holds if the measurement outcomes originate from a local hidden variable (LHV) model. As separable states allow a description by LHV models, a violation of a Bell inequality implies the presence of entanglement. In both cases, we define V as the violation of the corresponding inequality. That is, for a witness we have V(W) = - W while for a Bell inequality V(B) = B - Clhv . Then, the significance of an entanglement test can be defined as S= V E (1)

where E is the statistical error for the experiment. Clearly, E depends on the particular experimental implementation and on the error model used. Nevertheless, in any experiment S is a well characterized quantity and its notion is widely used in the literature, when the violation is expressed in terms of "standard deviations". Previously, much effort has been devoted to improving entanglement tests in order to achieve a higher violation. For instance, for entanglement witnesses a mature theory how to optimize witnesses has been developed [5]. Here, for a given witness W one tries to find a positive operator P which one can subtract from the witness, such that

