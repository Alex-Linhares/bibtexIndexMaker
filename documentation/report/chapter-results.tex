\chapter{Anàlisi de resultats}
\label{chapter:results}
En aquest capítol es mostren les principals proves realitzades per cadascuna de les tres parts del sistema que hem descrit als capítols anteriors




%%%% REFERENCE SEARCH %%%%
\section{Cerca de referències}
En primer lloc provarem com de bé ho fa el sistema a l'hora de cercar pàgines a Internet que continguin informació sobre un article concret. Els tests que hem dut a terme consisteixen en els passos següents:
\begin{enumerate}
\item{Obtenir una sèrie de consultes d'un llistat de documents PDF}
\item{Cercar cadascuna de les consultes amb: \textit{Google}, \textit{Bing} i \textit{Yahoo}}
\item{Per cadascun dels resultats obtinguts, analitzem si és bo o no}
\item{Comptabilitzem el número de consultes que han fet falta per obtenir el primer \textit{bon} resultat}
\end{enumerate}

Noteu que per tal classificar els resultats en bons i dolents nomes comprovem si part de la informació que volem es troba dins de la pàgina resultant. Aquesta no és una solució perfecta, però ens permet fer una aproximació sobre la quantitat de fitxers pels quals en podem trobar la referència.

\paragraph{}
Una altra qüestió sobre la implementació dels tests, és que els resultats obtinguts se solen repetir entre consultes del mateix article. Per estalviar temps i evitar fer moltes peticions seguides als mateixos servidors (que podrien resultar en un bloqueig), deixem uns segons entre petició i petició i emmagatzemem cada resultat de manera que només l'haguem de demanar una sola vegada. A més, en molts casos els resultats corresponen al mateix fitxer PDF del qual estem buscant informació i els hem d'ometre.

\paragraph{}
Les proves s'han realitzat per conjunts d'articles diferents agrupats depenent la seva capçalera, que és el que pot fer variar més els resultats obtinguts, i un últim grup amb articles de qualsevol tipus. Els gràfics de les figures \ref{fig:results:random-reslen} i \ref{fig:results:random-fqlen} a mostren els resultats d'aquest últim conjunt.
\begin{figure}[!ht]
\begin{center}
\includegraphics[width=0.9\textwidth]{figures/results:random-reslen.pdf}
\caption{Comparació de la qualitat dels resultats obtinguts segons la llargada de les consultes}
\label{fig:results:random-reslen}
\end{center}
\end{figure}

\paragraph{}
Tot i que en algunes ocasions els resultats bons retornats per \textit{Bing} o \textit{Yahoo} són superiors en nombre, en general, el cercador \textit{Google} ofereix major cobertura amb resultats sobre més articles.



\begin{figure}[!ht]
\begin{center}
\includegraphics[width=0.9\textwidth]{figures/results:random-fqlen.pdf}
\includegraphics[scale=0.8]{figures/results:search-legend.pdf}
\caption{Comparació del número de consultes necessàries abans de trobar bons resultats}
\label{fig:results:random-fqlen}
\end{center}
\end{figure}

\paragraph{}
Finalment, respecte les consultes veiem que com mes llargues són, el número de cerques que hem de fer per començar a obtenir bons resultats disminueix. De totes maneres, tal i com ja s'ha dit a la secció \ref{chapter:search:skip-queries}, per és bo que ens saltem les primeres consultes per evitar cercar amb el títol de l'article.








%%%% WRAPPER INDUCTION %%%%
\section{Generació de \textit{wrappers}}
\label{chapter:results:section:wrapperinduction}
Per provar aquesta part del sistema, hem creat de pàgines web amb informació d'articles diferents i amb la referència corresponent. Les pàgines que inclou un grup corresponen totes a la mateixa biblioteca digital. Per cadascun d'aquests conjunts hem importat les referències i hem donat l'ordre al sistema de generar els \textit{wrappers} pels camps de cada biblioteca. Les mostres no són significatives, però ens donen una idea per poder quantificar com de bé funciona l'aplicació dins l'entorn pel qual està pensat.

\paragraph{}
Els resultats d'aquestes proves corresponen a les puntuacions rebudes durant l'avaluació dels \textit{wrappers} i que permeten marcar un ordre d'elecció inicial a l'hora d'extreure referències. Com que de moment encara no hem fet proves amb pàgines que no s'han emprat per la generació (ho farem a la propera secció), parlarem de \textit{confiança} enlloc de correctesa. 

\paragraph{}
Com ja s'ha dit a la secció \ref{chapter:definition:section:bibtex}, els camps obligatoris que han de contenir les referències d'articles són: \textit{author}, \textit{title}, \textit{journal} i \textit{year}. A continuació mirarem dos d'aquests camps, la informació sobre la resta es poden trobar a l'apèndix \ref{appendix:results:section:wrapperinduction}.


\begin{figure}[!ht]
\begin{center}
\includegraphics[width=0.9\textwidth]{figures/results:coverage-journal.pdf}
\caption{Cobertura dels \textit{wrappers} pel camp \textit{journal}}
\label{fig:results:coverage-journal}
\end{center}
\end{figure}


\begin{figure}[!ht]
\begin{center}
\includegraphics[width=0.9\textwidth]{figures/results:coverage-year.pdf}
\caption{Cobertura dels \textit{wrappers} pel camp \textit{year}}
\label{fig:results:coverage-year}
\end{center}
\end{figure}




\paragraph{}
Si augmentem el número d'exemples a partir dels quals es generen els \textit{wrappers}, es produeix una explosió combinatòria que, com es pot veure a la figura \ref{fig:results:exec-time}, queda reflectida en els temps d'execució,

\begin{figure}[!ht]
\begin{center}
\includegraphics[width=0.9\textwidth]{figures/results:random-fqlen.pdf}
\caption{Comparació del temps d'execució necessari}
\label{fig:results:exec-time}
\end{center}
\end{figure}

\paragraph{}
Els camps pels quals es té més dificultat per generar \textit{wrappers} que funcionen són aquells consistents en números petits com poden ser el número de volum.
També li costa trobar anys en aquells casos en que la pàgina de la biblioteca conté múltiples camps amb el mateix valor, però corresponent a informacions diferents.

Això és degut 



%%%% REFERENCE EXTRACTION %%%%
\section{Extracció de referències}
text






