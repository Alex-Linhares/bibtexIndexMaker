\chapter{Cerca de referències}
\label{chapter:search}

%%%% EXTRACCIÓ PDF %%%%
\section{Extracció dels continguts d'un PDF}
El primer pas per aconseguir els objectius proposats és l'extracció del contingut d'un fitxer PDF. Aquest és un dels aspectes que han influït més en l'enfocament que hem donat al sistema, pels motius que es descriuen a continuació.
\paragraph{}
En un principi, la solució que vam plantejar va ser intentar extreure la referència bibliogràfica d'un document directament del fitxer PDF del qual es disposa. Tot i que a simple vista ja es veu que això pot tenir limitacions (e.g. informació que no es troba dins del text), després de veure com queden els articles al convertir-los a text ens vam allunyar encara més d'aquesta idea. Els llistats \ref{listing:examplePDFExtraction01} i \ref{listing:examplePDFExtraction02} mostren exemples de les capçaleres de dos articles diferents després d'haver extret el text del fitxer PDF en el que es trobaven. Com es pot veure, no hi ha cap tipus d'estructura que pugui deixar intuir quina part del text correspon a cada fragment d'informació que ens interessa.

\begin{lstlisting}[caption={Text corresponent a la capçalera d'un article després d'haver-lo extret d'un PDF}, label=listing:examplePDFExtraction01]
Characterization and Armstrong Relations for Degenerate Multivalued Dependencies Using Formal Concept Analysis
Jaume Baixeries and Jos´ Luis Balc´zar e a
Dept. Llenguatges i Sistemes Inform`tics, a Universitat Polit`cnica de Catalunya, e c/ Jordi Girona, 1-3, 08034 Barcelona {jbaixer, balqui}@lsi.upc.es

Abstract. Functional dependencies, a notion originated ...
\end{lstlisting}

\begin{lstlisting}[caption={Un altre exemple de text extret d'un PDF}, label=listing:examplePDFExtraction02]
2010 Second International Conference on Future Networks

Cloud Computing Research and Development Trend
Shuai Zhang Hebei Polytechnic University College of Science Hebei Polytechnic University NO.46 Xinhua West Street Tangshan 063009, Hebei Province China zhangshuai@heut.edu.cn Xuebin Chen Hebei Polytechnic University College of Science Hebei Polytechnic University NO.46 Xinhua West Street Tangshan 063009, Hebei Province China chxb@qq.comm
Abstract--With the development of parallel computing, distributed [...]
\end{lstlisting}

%%%% DIFICULTATS %%%%
\subsection{Dificultats}
Tot hi haver-hi diverses utilitats que permeten l'extracció del contingut d'un fitxer PDF en forma de text pla o HTML, totes presenten problemes similars als que es descriuen a continuació.  Les principals dificultats que es troben a l'hora d'obtenir el text són:
\begin{itemize}
\item{Caràcters especials}com ara Unicode o lligadures (e.g. \textit{fi} es representa com un sol caràcter)
\item{Sub/Superíndexs: }la majoria d'eines els extreuen com un número que forma part de la paraula. Per exemple: \textit{Joan$^{3}$} s'extreu com a \textit{Joan3}
\item{Flux del text dins del fitxer: }Hi ha casos en que el text es troba en diferents columnes i 
\item{Fragmentació de paràgrafs:}Relacionat amb el punt anterior. Hi ha ocasions on els paràgrafs es divideixen en un conjunt de línies segons com es troben posicionades dins del document.
\item{Fitxers protegits dels quals no es pot extreure el contingut}
\item{Documents escanejats:}Aquests fitxers només contenen imatge i, no en podem extreure el contingut amb les eines que hem provat.
\end{itemize}
A banda d'aquestes dificultats tècniques també hi influeix el fet que hi ha un número força reduït de programari lliure que ofereixi aquesta funcionalitat.

%%%% PROGRAMARI %%%%
\subsection{Programari}
Algunes de les opcions que hem tingut en compte a l'hora d'escollir una llibreria o aplicació d'extracció de text han estat: \textit{PyPDF}, \textit{PDFMiner} o \textit{PDFBox}, tot i que finalment ens hem decantat per \textit{xPDF}.

\paragraph{}
\textit{xPDF} és un conjunt d'eines executables des de la línia de comandes que permeten extreure text i altres elements dels fitxers PDF. Es distribueixen sota la llicència GPL v.2 i hi ha binaris tant per Windows com per Linux (que també funcionen per Mac OS). El motiu principal pel qual hem escollit aquesta eina és la qualitat dels resultats. En especial, el fet que no separa els paràgrams en diferents línies i que en la majoria dels casos respecta el flux del text dins del document. 

\paragraph{}
Pel que fa als caràcters especials, transforma bé les lligadures en múltiples caràcters, però té problemes amb la codificació Unicode. Donat que la majoria dels articles científics estan escrits en anglès, aquest és un problema que hem decidit obviar.


%%%% CONSULTES %%%%
 \section{Consultes}
 \label{section:chapter-search:consultes}
El punt més important per poder cercar referències bibliogràfiques a Internet és ser capaços de generar consultes que retornin bons resultats. Una primera idea pot consistir en cercar segons el títol de l'article del qual volem informació. El problema és que bona part dels resultats corresponen a pàgines que fan una referència a aquest article, però que no en donen gaires detalls.  Com que a l'extreure el text del PDF la resta de les dades de la capçalera queden desfigurades, és difícil itzar-les per fer les consultes. 
\paragraph{}
Per una altra banda, si intentem fer consultes a partir del contingut del propi article ens trobem amb que en molts casos, els cercadors no el tenen indexat. Una tercera opció, que és la que utilitzem, consisteix en generar les consultes a partir del resum o \textit{abstract} que acompanya a la majoria d'articles i que també acostuma a aparéixer a les pàgines que contenen la referència.
\paragraph{}
Però com podem saber quina part del text que hem extret correspon al resum? Tot i que en molts articles el primer paràgraf va precedit de la paraula \textit{Abstract}, també n'hi ha molts altres que van precedits d'una paraula completament diferent (e.g. resum o \textit{summary}) o bé per cap. Per tal que el sistema sigui el més general possible, enlloc de fixar-nos en paraules concretes fem servir una expressió regular molt simple que permet trobar cadenes amb un número de paraules determinat. 

\paragraph{}
Un dels trets característics de les capçaleres dels articles una vegada n'hem extret el text és que contenen un nombre elevat de símbols especials. Això ens pot ajudar a distingir entre les parts corresponents a la capçalera i resum. L'expressió regular que obté les consultes és: \verb=([\w()?!]+[ ]){min,max}= i agafarà seqüències de \textit{min} a \textit{max} paraules separades per un espai i formades per caràcters alfanumèrics i un nombre limitat de símbols. Els paràmetres \textit{min} i \textit{max} són configurables. Òbviament, les consultes que ens dóna aquesta expressió no sempre són bones i per tal de contrarrestar aquests errors, en generem un cert nombre que anirem utilitzant mentre no s'obtinguin resultats satisfactoris. De totes maneres, tal i com es pot veure al capítol \ref{chapter:results}, no és necessari ni generar moltes consultes ni cal que aquestes siguin gaire llargues.

\paragraph{}
A continuació es llisten cinc consultes extretes d'un article d'exemple. Noteu que les consultes s'envolten de cometes dobles, la forma habitual d'indicar als cercadors que les coincidències han de ser exactes.
\begin{itemize}
\item{``are known to admit interesting characterizations in terms of Formal''}
\item{``natural extensions of the notion of functional dependency are the''}
\item{``We propose here a new Galois''}
\item{``which gives rise to a formal concept lattice corresponding precisely''}
\item{``o the degenerate multivalued dependencies that hold in the relation''}
\end{itemize}

\paragraph{}
En molts casos, l'expressió regular anterior també dóna coincidències pel títol de l'article. Per evitar-ho, hem definit un altre paràmetre que defineix el nombre de consultes a saltar-se des del principi de l'article.


%%%% CERCADORS %%%%
\section{Cercadors}
\label{section:search:searchers}
El següent pas després d'haver obtingut un conjunt de consultes és utilitzar-les amb un cercador per tal d'obtenir pàgines amb informació de la referència que volem aconseguir. Al capítol d'introducció, hem esmentat que hi ha cercadors com ara \textit{Google Scholar} o \textit{Microsoft Academic Search} on els resultats només corresponen a publicacions. En un principi, ens va semblar raonable intentar fer ús d'aquests serveis per poder aconseguir els nostres objectius.

\paragraph{}
El principal problema que hem trobat amb aquests  és que no han publicat cap API per tal de permetre les consultes automàtiques des d'aplicacions de tercers. Tot i que hi ha solucions a aquest problema, van en contra dels termes i condicions i els servidors bloquegen massa consultes seguides. Per tant, hem descartat aquesta opció.

\paragraph{}
Així doncs, ens quedem amb els cercadors habituals i hem preparat la nostra aplicació per tal d'utilitzar les APIs de \textit{Google}, \textit{Yahoo} i \textit{Bing}. Els principals inconvenients són que retornen qualsevol tipus de pàgina i que no tenen indexades algunes blioteques digitals,. Tot i així, també podem aconseguir bons resultats amb l'ús de les consultes adequades.  


\subsection{Ordenació de resultats}
La majoria de vegades, no ens convindrà tant l'ordre dels resultats donat pels diferents cercadors sinó que voldrem processar les pàgines per les quals tenim regles d'extracció d'informació. És per això que 

\subsection{Altres Ajustaments}
Depenent de ldel tipus de fitxers dels que disposem la qualitat dels resultats obtinguts amb els cercadors poden variar considerablement. Això suposa la necessitat d'ajustar alguns paràmetres per tal de poder adaptar el sistema a l'ús de cadascú. A la secció sobre la generació de consultes (\ref{section:chapter-search:consultes}), ja hem comentat la possibilitat d'ajustar el mínim i màxim de termes a cercar, però hi ha altres opcions que es poden configurar.

\paragraph{}
En algunes ocasions, es dóna el cas que la consulta generada no és prou restrictiva, ja sigui perquè no és prou llarga o bé perquè està formada per paraules molt generals. Al cercar amb aquestes consultes s'obté una llarga llista de resultats, la majoria dels quals no tenen res a veure amb la informació que estem buscant. Per contrarestar-ho, hi ha la possibilitat d'indicar al sistema que ometi els resultats i provi amb la següent consulta. A l'hora d'assignar el valor d'aquest paràmetre, també s'haurà de tenir en compte el tipus d'articles dels que es vol informació. Per exemple, articles populars tindran un número de coincidències rellevants gran i, per tant, haurem d'assignar un valor relativament alt, ja que un valor baix farà que descartem resultats bons. En canvi, per articles poc corrents, ens interessarà el contrari.

\paragraph{}
Per una altra banda,  hi ha ocasions en que els cercadors tenen tendència a retornar resultats que, tot i coincidir amb la consulta que li hem donat, corresponen a una pàgina que no ens aporta massa informació. Per tal d'ajudar a l'aplicació a descartar resultats dolents, podem indicar-li pàgines que volem ometre a partir d'una llista negra. Per exemple, sabem que les pàgines sobre els autors de la biblioteca digital \textit{ACM Portal} contenen un llistat de tots els articles d'un mateix autor, però que no contenen suficient informació com per extreure referències. En aquest cas voldrem descartar els resultats que comencen per \href{http://portal.acm.org/author\_page.cfm?id=}{http://portal.acm.org/author\_page.cfm?id=id-autor}.

\section{\textit{Multithreading}}
Un dels inconvenients més grans que implica el fet d'haver d'accedir a Internet, és que el temps perdut esperant dades és molt alt. Per reduir-lo, s'ha estudiat la possibilitat d'utilitzar diferents fils d'execució per fer més d'una consulta de forma més o menys simultània. La taula següent mostra una comparativa del temps necessari per obtenir mútliples pàgines web de forma seqüencial o bé utilitzant fins a cinc fils d'execució diferents. Les pàgines pàgines corresponen a consultes aleatòries a \textit{Google} per evitar l'efecte dels \textit{proxies} i \textit{caches}. 

    \begin{center}
    \begin{tabular}{|r|r|r|r|r|r|r|r|}
        \hline
        \multicolumn{2}{|c|}{2 pàgines} & \multicolumn{2}{|c|}{5 pàgines} & \multicolumn{2}{|c|}{10 pàgines} & \multicolumn{2}{|c|}{20 pàgines} \\
        \hline
        Seq. & 5 Threads          & Seq. & 5 Threads          & Seq. & 5 Threads           & Seq. & 5 Threads \\
        \hline
        \hline
        0.9010 & 0.5481 & 2.1830 & 0.6612 & 4.3153 & 1.5914 & 7.9295 & 2.5949 \\
        0.7467 & 0.3795 & 2.1558 & 0.7441 & 4.3186 & 1.2311 & 8.5483 & 2.1958 \\ 
        0.7678 & 0.5641 & 2.0645 & 0.5383 & 9.2930 & 1.4415 & 8.7202 & 2.5749 \\
        0.7421 & 0.3876 & 2.0684 & 0.8551 & 4.9859 & 1.5294 & 8.4732 & 2.2841 \\
        0.9674 & 0.5477 & 2.1510 & 0.8550 & 5.3600 & 1.3116 & 9.2901 & 2.2257 \\
        \hline
        \multicolumn{8}{|l|}{Mitjana:} \\
        \hline
        0.8250 & 0.4854 & 2.1246 & 0.7307 & 5.6546 & 1.4210 & 8.5923 & 2.3751 \\
        \hline
        \multicolumn{8}{|l|}{Guany:} \\
        \hline
        \multicolumn{2}{|c|}{\textbf{-44.96\%}} &  \multicolumn{2}{|c|}{\textbf{-65.6\%}} &  \multicolumn{2}{|c|}{\textbf{-74.87\%}} &  \multicolumn{2}{|c|}{\textbf{-72.35\%}} \\
        \hline
    \end{tabular}
    \end{center}

Tot i que auqestes proves no siguin gaire riguroses, són suficients per poder-nos fer una idea força clara sobre la millora que s'obté utilitzant múltiples fils respecte no fer-ho.

\paragraph{}
Sobre la forma d'implementar-ho, hem creat un \textit{pool} amb un número màxim configurable de fils d'execució que es van reutilitzant mentre queden referències per extreure. Bàsicament, tenim una cua amb les rutes als fitxers PDF i una cua de sortida amb el resultat d'extreure les referències. Cada \textit{thread} va processant fitxers de la cua d'entrada mentre aquesta no és buida. El número de fils màxim dependrà del tipus de connexió del que es disposi.
